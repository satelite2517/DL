{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.004300 002 Deep Learning Assignment #1<br> Part 2: Training Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Hyungi Kim, September 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PDF file.**\n",
    "\n",
    "In this notebook, you will learn how to train convolutional neural networks (CNNs) for classifying images in the CIFAR-10 dataset. <br>\n",
    "There are **3 sections**, and in each section, you need to follow the instructions to complete the skeleton codes and explain them.\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results. \n",
    "\n",
    "### Some helpful tutorials and references for assignment #1-3:\n",
    "- [1] Pytorch official documentation. [[link]](https://pytorch.org/docs/stable/index.html)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Szegedy et al., \"Going deeper with convolutions\", CVPR 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets\n",
    "The CIFAR-10 dataset will be downloaded automatically if it is not located in the *data* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(np.transpose(npimg, (1, 2, 0)).shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "images, labels = next(iter(dataloader_train))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(classes[labels[j]] for j in range(8)))\n",
    "# print size of single image\n",
    "print(images[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a small CNN model\n",
    "\n",
    "#### CNN architecture in order:\n",
    "* 7x7 Convolutional layer with 8 filters, strides of 1, and ReLU activation\n",
    "* 2x2 Max pooling layer with strides of 2\n",
    "* 4x4 Convolutional layer with 16 filters, strides of 1, and ReLU activation\n",
    "* 2x2 Max pooling layer with strides of 2\n",
    "* Fully connected layer with 100 output units and ReLU activation\n",
    "* Fully connected layer with 80 output units and ReLU activation\n",
    "* Fully connected layer with 10 output units \n",
    "* You can use any padding option.\n",
    "\n",
    "#### Training setup:\n",
    "* Loss function: Softmax cross entropy\n",
    "* Optimizer: Gradient descent with 0.001 learning rate\n",
    "* Batch size: 64\n",
    "* Training epoch: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the network\n",
    "\n",
    "def train(net, dataloader_train, max_epoch, crit, optimizer, device, model_path='./cifar_net.pt'):\n",
    "\n",
    "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader_train, 0):\n",
    "            # get the inputs; data is a list of [inputs, targets]\n",
    "            inputs, targets = data\n",
    "        \n",
    "            # Training on GPU\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = crit(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            print_every = 100\n",
    "            if (i + 1) % print_every == 0:    # print every 100 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1}] loss: {(running_loss / print_every):.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(), model_path)\n",
    "    print('Saved Trained Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate accuracy\n",
    "def test(net, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            # Inference on GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f'Accuracy of the network on the {total} test images: {(100 * correct / total):.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_checkpoints/cifar_net.pt'\n",
    "epoch = 5\n",
    "\n",
    "# initialize model\n",
    "net = Net()\n",
    "\n",
    "# Training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "train(net, dataloader_train, epoch, criterion, optimizer, device, PATH)\n",
    "\n",
    "# load trained model then test\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "test(net, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"3-1\"></a>3-1. Design an Inception module\n",
    "\n",
    "In this section, you will implement a little more complex CNN model with an `Inception module`. <br>\n",
    "\n",
    "![Inception_module](imgs/Inception.png)\n",
    "\n",
    "Using the code provided as guidance, <br>\n",
    "Define an `inception module`, which is the building block of **Inception model (a.k.a GoogLeNet)**, the winner of ILSVRC14. <br>\n",
    "\n",
    "\n",
    "#### Inception model architecture:\n",
    "* CNN model consists with stem layer, inception module, and fully connected layer\n",
    "* Stem layer with\n",
    "    * conv-pooling-conv-pooling\n",
    "* `Inception module` with \n",
    "    * 3(or 4) main convolutions (blue blocks in the Figure(a))\n",
    "    * 3 dimensionality reduction convolutions (yellow blocks in the Figure(a))\n",
    "    * 3x3 max pooling block (red blocks in the Figure(a))\n",
    "    * Batch Nomalization and ReLU activation after all conv layer\n",
    "* Fully connected layer with 10 output units and linear activation\n",
    "* Choose the proper padding option on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "About parameter\n",
    "in_planes : # of input channel\n",
    "n1xn1 : # of output channel for first branch\n",
    "n3xn3_blue : # of output channel for second branch's 1x1 conv layer\n",
    "n3xn3 : # of output channel for second branch\n",
    "n5xn5_blue : # of output channel for third branch's 1x1 conv layer\n",
    "n5xn5 : # of output channel for third branch\n",
    "pool_planes : # of output channel for fourth branch\n",
    "\n",
    "'''\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3_blue, n3x3, n5x5_blue, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "        )\n",
    "        self.inception_blocks = nn.Sequential(\n",
    "            Inception(192, 64, 96, 128, 16, 32, 32),  # Inception 3a\n",
    "            Inception(256, 128, 128, 192, 32, 96, 64),  # Inception 3b\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # MaxPool\n",
    "            Inception(480, 192, 96, 208, 16, 48, 64),  # Inception 4a\n",
    "            Inception(512, 160, 112, 224, 24, 64, 64),  # Inception 4b\n",
    "            Inception(512, 128, 128, 256, 24, 64, 64),  # Inception 4c\n",
    "            Inception(512, 112, 144, 288, 32, 64, 64),  # Inception 4d\n",
    "            Inception(528, 256, 160, 320, 32, 128, 128),  # Inception 4e\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # MaxPool\n",
    "            Inception(832, 256, 160, 320, 32, 128, 128),  # Inception 5a\n",
    "            Inception(832, 384, 192, 384, 48, 128, 128),  # Inception 5b\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(nn.Dropout(0.4), nn.Linear(1024, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layers(x)\n",
    "        x = self.inception_blocks(x)\n",
    "        x = self.avgpool(x).view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_checkpoints/inception_net.pt'\n",
    "epoch = 5\n",
    "\n",
    "# initialize model\n",
    "inception_net = InceptionNet()\n",
    "inception_net = inception_net.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(inception_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "train(inception_net, dataloader_train, epoch, criterion, optimizer, device, PATH)\n",
    "# Test\n",
    "inception_net.load_state_dict(torch.load(PATH))\n",
    "test(inception_net, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"3-2\"></a>3-2. Design an Residual Block module\n",
    "\n",
    "In this section, you will implement a little more complex CNN model with a `Residual block`. <br>\n",
    "\n",
    "![Residual_block](imgs/Residualblock.png)\n",
    "\n",
    "Using the code provided as guidance, <br>\n",
    "Define a `residual block module`, which is the building block of **Residual neural network (a.k.a ResNet)**, the winner of ILSVRC15. <br>\n",
    "\n",
    "\n",
    "#### ResNet architecture:\n",
    "* A residual block consists of convolutional layers, bach normalization, ReLU actication functions, and Shortcut Connection.\n",
    "* Define the Short Connection which directly connects the input of the block to the output.\n",
    "* The shortcut module must be sequential layers that contain:\n",
    "    * 1 convolution of kernel size 1\n",
    "    * 1 batch normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the residual block class\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # The first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # The second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection (identity mapping)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            ############################################################################## \n",
    "            #                        IMPLEMENT OF YOUR CODE                       #\n",
    "            ##############################################################################\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            ############################################################################## \n",
    "            #                           END OF YOUR CODE                          #\n",
    "            ##############################################################################\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass through the first convolutional layer\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        # Pass through the second convolutional layer\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        # Add the output and the shortcut and pass it through a relu activation layer for the final output. (Residual connection implementation)\n",
    "        ############################################################################## \n",
    "            #                        IMPLEMENT OF YOUR CODE                       #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ############################################################################## \n",
    "            #                        IMPLEMENT OF YOUR CODE                       #\n",
    "        ##############################################################################\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, 2, 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(3, 2, 1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = [block(self.in_channels, out_channels, stride)]\n",
    "        self.in_channels = out_channels\n",
    "        layers += [block(out_channels, out_channels) for _ in range(1, blocks)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        return self.fc(torch.flatten(x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_checkpoints/resnet.pt'\n",
    "epoch = 5\n",
    "\n",
    "# initialize model\n",
    "resnet = ResNet(ResidualBlock, [2, 2, 2, 2], 10)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "train(resnet, dataloader_train, epoch, criterion, optimizer, device, PATH)\n",
    "# Test\n",
    "resnet.load_state_dict(torch.load(PATH))\n",
    "test(resnet, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"3-3\"></a>3-3. Design a better model on CIFAR-10\n",
    "\n",
    "Now it's your job to experiment with CNNs to train a model that achieves **<font color=red>>= 73% accuracy on the test set</font>** of CIFAR-10. <br> You can reuse the implemented functions from above.\n",
    "\n",
    "### Things you can try to change:\n",
    "- Filter size\n",
    "- Number of filters\n",
    "- Pooling vs Strided Convolution\n",
    "- Network architectures\n",
    "- Optimizers\n",
    "- Activation functions\n",
    "- Regularizations\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model\n",
    "class BetterNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet, self).__init__()\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_checkpoints/better_net.pt'\n",
    "epoch = 5\n",
    "\n",
    "# initialize model\n",
    "betternet = BetterNet()\n",
    "betternet = betternet.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(betternet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "train(betternet, dataloader_train, epoch, criterion, optimizer, device, PATH)\n",
    "# Test\n",
    "betternet.load_state_dict(torch.load(PATH))\n",
    "test(betternet, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe what you did here\n",
    "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network.\n",
    "\n",
    "You can write in Korean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tell us here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
